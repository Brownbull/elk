input {
  file {
    path => "/home/brownbull/ELK/L/pipeInfra/data/10.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}
filter {
  csv {
    separator => ","
    autodetect_column_names => false
    autogenerate_column_names => false
    skip_header => true
    columns => ["server","date","hour","percFreeCPU","percFreeRAM","percFreeHDD",
      "totalSpaceGb","availableSpaceGb","conections","Other"]
  }
  if [server] == "Servidor" {
    drop { }
  }
  mutate {
    add_field => {
      "timestamp" => "%{date} %{hour}"
    }
    gsub => [
      # replace backslashes, question marks, hashes, and minuses
      # with a dot "."
      "percFreeCPU", "[%]", "",
      "percFreeRAM", "[%]", "",
      "percFreeHDD", "[%]", ""
    ]
    convert => {
      "percFreeCPU" => "integer"
      "percFreeRAM" => "integer"
      "percFreeHDD" => "integer"
      "totalSpaceGb" => "integer"
      "availableSpaceGb" => "float"
    }
    remove_field => ["date","hour","Other"]
  }
  date {
        locale => "en"
        match => ["date",  "MM/dd/yyyy"]
        target => "date"
  }
  date {
        locale => "en"
        match => ["hour",  "HH:mm"]
        target => "hour"
  }
  date {
    match => ["timestamp", "MM/dd/yyyy HH:mm"]
    remove_field => ["timestamp"]
  }
}
output {
  file {
    codec => "json"
    path => "/home/brownbull/ELK/L/pipeInfra/10.json"
  }
   elasticsearch {
    hosts => ["localhost:9200"]
    index => "infra10"
  }
 stdout { }
}    
